{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen   \n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import requests\n",
    "from sodapy import Socrata\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load/Retrieve all data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve data from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DOB Job Application Filings\n",
    "## https://data.cityofnewyork.us/Housing-Development/DOB-Job-Application-Filings/ic3t-wcy2/data\n",
    "data_set='ic3t-wcy2'\n",
    "data_url='data.cityofnewyork.us'\n",
    "# NYC Data API key - input key as 'app_token'\n",
    "#from config import app_token\n",
    "#app_token=app_token\n",
    "app_token = '0h1v8vN3cR81KItbjfjYgRrAH'\n",
    "\n",
    "client = Socrata(data_url,app_token)\n",
    "# columns to retrieve from the dataset\n",
    "cols = 'job__, doc__, house__, street_name, job_type, block, lot, bin__, borough, latest_action_date, pre__filing_date, owner_s_first_name, owner_s_last_name, owner_s_business_name'\n",
    "results = client.get(data_set, job_type=\"NB\", select = cols, limit=200000)\n",
    "df = pd.json_normalize(results)\n",
    "\n",
    "## Filter filing data to 2020 NBs\n",
    "df = df[df[\"job_type\"]==\"NB\"]\n",
    "df.latest_action_date = pd.to_datetime(df.latest_action_date)\n",
    "df.pre__filing_date = pd.to_datetime(df.pre__filing_date)\n",
    "df['year'] = pd.DatetimeIndex(df['pre__filing_date']).year\n",
    "df = df[df['year']==2021]\n",
    "df = df[df['doc__']==\"01\"]\n",
    "\n",
    "df.to_csv(\"raw-data/NB-2021.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.today()\n",
    "s = today.strftime(\"%Y/%m/%d\")\n",
    "date = datetime.strptime(s, \"%Y/%m/%d\")\n",
    "modified_date = date - timedelta(days=365*3)\n",
    "back_to_date = datetime.strftime(modified_date, \"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_var = \"good_through_date >\" + ' \"' + back_to_date + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ACRIS - Real Property Legals\n",
    "## https://data.cityofnewyork.us/City-Government/ACRIS-Real-Property-Legals/8h5j-fqxa/data\n",
    "data_url='data.cityofnewyork.us'\n",
    "data_set='8h5j-fqxa'\n",
    "client = Socrata(data_url,app_token)\n",
    "client.timeout = 300\n",
    "results_legals = client.get(data_set, where= where_var, select = 'borough, block, lot, street_number, street_name, document_id', limit=2000000)\n",
    "rpl = pd.json_normalize(results_legals)\n",
    "\n",
    "rpl.to_csv(\"raw-data/real_prop_legals.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ACRIS - Real Property Parties\n",
    "## https://data.cityofnewyork.us/City-Government/ACRIS-Real-Property-Parties/636b-3b5g/data\n",
    "data_set='636b-3b5g'\n",
    "data_url='data.cityofnewyork.us'\n",
    "client = Socrata(data_url,app_token)\n",
    "client.timeout = 300\n",
    "results = client.get(data_set, where= where_var, select = 'good_through_date, document_id, name, party_type',limit=43000000)\n",
    "rpp = pd.json_normalize(results)\n",
    "\n",
    "rpp.to_csv(\"raw-data/real_prop_parties.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ACRIS - Real Property Master\n",
    "## https://data.cityofnewyork.us/City-Government/ACRIS-Real-Property-Master/bnx9-e6tj/data\n",
    "data_url='data.cityofnewyork.us'\n",
    "data_set='bnx9-e6tj'\n",
    "client.timeout = 300\n",
    "results_rpm = client.get(data_set,where= where_var, select = 'document_date, doc_type, document_id', limit=16000000)\n",
    "rpm = pd.json_normalize(results_rpm)\n",
    "\n",
    "rpm.to_csv(\"raw-data/real_prop_master.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ACRIS - Document Control Codes\n",
    "## https://data.cityofnewyork.us/City-Government/ACRIS-Document-Control-Codes/7isb-wh4c/data\n",
    "data_url='data.cityofnewyork.us'\n",
    "data_set='7isb-wh4c'\n",
    "client.timeout = 300\n",
    "results_dcc = client.get(data_set, limit=150)\n",
    "dcc = pd.json_normalize(results_dcc)\n",
    "\n",
    "dcc.to_csv(\"raw-data/document_control_codes.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### saved data from APIs\n",
    "df = pd.read_csv(\"raw-data/NB-2021.csv\")\n",
    "rpl = pd.read_csv(\"./raw-data/real_prop_legals.csv\")\n",
    "rpp = pd.read_csv(\"raw-data/real_prop_parties.csv\")\n",
    "rpm = pd.read_csv(\"./raw-data/real_prop_master.csv\")\n",
    "dcc = pd.read_csv(\"raw-data/document_control_codes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(nb_filing, rpp, rpl, rpm, dcc):\n",
    "    '''\n",
    "    cleans the datasets necessary for the model\n",
    "    \n",
    "    Keyword arguments:\n",
    "    nb_filing -- DOB Job Application Filings (NYC OpenData) dataframe\n",
    "    rpp -- ACRIS - Real Property Parties (NYC OpenData) dataframe\n",
    "    rpl -- ACRIS - Real Property Legals (NYC OpenData) dataframe\n",
    "    rpm -- ACRIS - Real Property Master (NYC OpenData) dataframe\n",
    "    dcc -- ACRIS - Document Control Codes (NYC OpenData) dataframe\n",
    "    '''\n",
    "    \n",
    "    # Add BBL code\n",
    "    nb_filing['block'] = nb_filing.block.astype(int).astype(str)\n",
    "    nb_filing['lot'] = nb_filing.lot.astype(int).astype(str)\n",
    "    nb_filing['borough_code'] = 0\n",
    "    nb_filing.loc[nb_filing['borough']==\"MANHATTAN\", 'borough_code'] = 1\n",
    "    nb_filing.loc[nb_filing['borough']==\"BRONX\", 'borough_code'] = 2\n",
    "    nb_filing.loc[nb_filing['borough']==\"BROOKLYN\", 'borough_code'] = 3\n",
    "    nb_filing.loc[nb_filing['borough']==\"QUEENS\", 'borough_code'] = 4\n",
    "    nb_filing.loc[nb_filing['borough']==\"STATEN ISLAND\", 'borough_code'] = 5\n",
    "    nb_filing['BBL'] = nb_filing['borough_code'].astype(str) + nb_filing['block'].astype(str).str.zfill(5) + nb_filing['lot'].astype(str).str.zfill(4)\n",
    "    rpl['BBL'] = rpl['borough'].astype(str) + rpl['block'].astype(str).str.zfill(5) + rpl['lot'].astype(str).str.zfill(4)\n",
    "\n",
    "    # convert to date\n",
    "    rpp['date'] = pd.to_datetime(rpp.good_through_date)\n",
    "    rpp = rpp.sort_values('date', ascending=False)\n",
    "    \n",
    "    # Remove leading and ending whitespaces\n",
    "    nb_filing.owner_s_business_name = [str(name).strip() for name in nb_filing.owner_s_business_name]\n",
    "    nb_filing.house__ = [str(house_num).strip() for house_num in nb_filing.house__]\n",
    "    nb_filing.street_name = [str(name).strip() for name in nb_filing.street_name]\n",
    "    nb_filing.owner_s_first_name = [str(name).strip() for name in nb_filing.owner_s_first_name]\n",
    "    nb_filing.owner_s_last_name = [str(name).strip() for name in nb_filing.owner_s_last_name]\n",
    "\n",
    "    rpp.name = [str(name).strip() for name in rpp.name] \n",
    "\n",
    "    rpl.street_number = [str(name).strip() for name in rpl.street_number]\n",
    "    rpl.street_name = [str(name).strip() for name in rpl.street_name]\n",
    "\n",
    "    rpp.document_id = [name.strip() for name in rpp.document_id] \n",
    "    rpl.document_id = [name.strip() for name in rpl.document_id] \n",
    "    rpm.document_id = [name.strip() for name in rpm.document_id]\n",
    "    \n",
    "    # add columns\n",
    "    nb_filing['name'] = nb_filing['owner_s_first_name'] + \" \" + nb_filing['owner_s_last_name']\n",
    "    nb_filing[\"NB_ADDRESS\"] = nb_filing[\"house__\"].map(str) + ' ' + nb_filing[\"street_name\"].map(str)\n",
    "    \n",
    "    # fix N/A in nb_filing datset\n",
    "    conditions = [(nb_filing.owner_s_business_name == \"N/A\"),\n",
    "                  (nb_filing.owner_s_business_name.isna()),\n",
    "                  (nb_filing.owner_s_business_name != \"N/A\")]\n",
    "\n",
    "    choices = [nb_filing.name, nb_filing.name, nb_filing.owner_s_business_name]\n",
    "    nb_filing[\"owner_s_business_name\"] = np.select(conditions, choices)\n",
    "    \n",
    "    # drop duplicate BBLs\n",
    "    nb_filing = df.drop_duplicates(\"BBL\")\n",
    "    \n",
    "    # subset datasets\n",
    "    rpm = rpm[[\"document_id\", \"doc_type\", \"document_date\"]]\n",
    "    dcc = dcc.rename(columns={\"doc__type\": \"doc_type\"})\n",
    "    # add Document Control Codes to Real Property Masters\n",
    "    rpm = pd.merge(rpm, dcc, on=\"doc_type\", how=\"left\")\n",
    "    \n",
    "    # clean up date\n",
    "    rpm['doc_date'] = pd.to_datetime(rpm.document_date, errors = 'coerce')\n",
    "\n",
    "    # rearrange columns so date columns are by each other\n",
    "    rpm = rpm[['document_id','doc_type','document_date', 'doc_date','record_type','doc__type_description',\n",
    "     'class_code_description','party1_type','party2_type','party3_type']]\n",
    "    \n",
    "    return(nb_filing, rpp, rpl, rpm, dcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, rpp, rpl, rpm, dcc = clean_data(df, rpp, rpl, rpm, dcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job__</th>\n",
       "      <th>doc__</th>\n",
       "      <th>house__</th>\n",
       "      <th>street_name</th>\n",
       "      <th>job_type</th>\n",
       "      <th>block</th>\n",
       "      <th>lot</th>\n",
       "      <th>bin__</th>\n",
       "      <th>borough</th>\n",
       "      <th>latest_action_date</th>\n",
       "      <th>pre__filing_date</th>\n",
       "      <th>owner_s_first_name</th>\n",
       "      <th>owner_s_last_name</th>\n",
       "      <th>owner_s_business_name</th>\n",
       "      <th>year</th>\n",
       "      <th>borough_code</th>\n",
       "      <th>BBL</th>\n",
       "      <th>name</th>\n",
       "      <th>NB_ADDRESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>440660571</td>\n",
       "      <td>1</td>\n",
       "      <td>150-04</td>\n",
       "      <td>BEAVER ROAD</td>\n",
       "      <td>NB</td>\n",
       "      <td>10107</td>\n",
       "      <td>79</td>\n",
       "      <td>4215639</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>STEPHEN</td>\n",
       "      <td>BELLINO</td>\n",
       "      <td>LIBERTY ASHES INC.</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>4101070079</td>\n",
       "      <td>STEPHEN BELLINO</td>\n",
       "      <td>150-04 BEAVER ROAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       job__  doc__ house__  street_name job_type  block lot    bin__ borough  \\\n",
       "0  440660571      1  150-04  BEAVER ROAD       NB  10107  79  4215639  QUEENS   \n",
       "\n",
       "  latest_action_date pre__filing_date owner_s_first_name owner_s_last_name  \\\n",
       "0         2021-01-13       2021-01-04            STEPHEN           BELLINO   \n",
       "\n",
       "  owner_s_business_name  year  borough_code         BBL             name  \\\n",
       "0    LIBERTY ASHES INC.  2021             4  4101070079  STEPHEN BELLINO   \n",
       "\n",
       "           NB_ADDRESS  \n",
       "0  150-04 BEAVER ROAD  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download digital NYC Digital Tax Map shapfile from:\n",
    "### https://data.cityofnewyork.us/widgets/smk3-tmxj\n",
    "\n",
    "URL = \\\n",
    "    'https://data.cityofnewyork.us/download/smk3-tmxj/application%2Fzip'\n",
    "\n",
    "# open and save the zip file onto computer\n",
    "url = urlopen(URL)\n",
    "output = open('./raw-data/Digital_Tax_Map_'+today.strftime(\"%Y%m%d\")+'.zip', 'wb')           \n",
    "output.write(url.read())\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two shapefiles you will need from the zip folder are: \n",
    "- 'DTM_Tax_Lot_Polygon'  \n",
    "- 'DTM_Tax_Block_Polygon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set path to the downloaded shapefile\n",
    "path_read_zip = './raw-data/Digital_Tax_Map_'+today.strftime(\"%Y%m%d\")+'.zip'\n",
    "\n",
    "tax_lot = gpd.read_file('zip://' + path_read_zip + \"!DTM_Tax_Lot_Polygon.shp\")\n",
    "tax_block = gpd.read_file('zip://' + path_read_zip + \"!DTM_Tax_Block_Polygon.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set output path for final shapefile\n",
    "shapefile_saved_path = \"output-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset NYC Tax lot shapefile to only NB lots\n",
    "lot_sub = tax_lot[tax_lot.BBL.isin(df.BBL.tolist())]\n",
    "## spatial join NB lots with NYC Block polygons\n",
    "block_sub = gpd.sjoin(tax_block, lot_sub)\n",
    "block_sub = block_sub.drop(['index_right'], axis=1)\n",
    "## spatial join the selected Block polygons with intersecting lots\n",
    "## to get all lots within the block\n",
    "tax_lot = tax_lot[~tax_lot.geometry.isna()]\n",
    "tax_shp = gpd.sjoin(tax_lot, block_sub)\n",
    "\n",
    "## clean output\n",
    "tax_shp = tax_shp[tax_shp.columns.drop(list(tax_shp.filter(regex='right')))]\n",
    "tax_shp = tax_shp.rename(columns={\"LOT_left\": \"LOT\", \"BBL_left\": \"BBL\"})\n",
    "tax_shp = tax_shp[[\"BORO\", \"BLOCK\", \"LOT\", \"BBL\", \"geometry\"]]\n",
    "tax_shp = tax_shp.drop_duplicates()\n",
    "\n",
    "### save final shapefile\n",
    "tax_shp.to_file(shapefile_saved_path + \"NB_lots_blocks.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in saved shapefile created with above steps\n",
    "tax_shp = gpd.read_file(shapefile_saved_path +\"NB_lots_blocks.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARQAAAEFCAYAAAAi+hhHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbk0lEQVR4nO3deZCcd33n8fe35z50zKVrdIxO25IQtiTLso0PTGwMcQxkISiVBO3imIWwXmADWbzewqkklcI4gQpJDMUuXnAKEuzFgDbByIOCbcpYsiVZI0vWfVqWrBnNjEajGWnO3/7xPCP1jFrTPd1P99PH51XVpZ7fc/S3Wz3fefrp53k+5pxDRCQIkbALEJH8oYYiIoFRQxGRwKihiEhg1FBEJDDFYRcQtPr6etfU1BR2GSJ5a9u2bWeccw2xpuVdQ2lqamLr1q1hlyGSt8zs2NWm6SOPiARGDUVEAqOGIiKBUUMRkcCooYhIYNRQRCQwaigiEhg1FBEJjBqKFKzDrd08s+Wqx2hJEtRQpGBVFEeoLM+7g8VDpVdTCtbM2ip+u7Yq7DLyirZQRCQwaigiEhg1FBEJjBqKSJq909bOb3YdDLuMjNBOWZE0m9FQxwUrjF+1uFsoZjbHzH5lZnvMbLeZfS5q2kNmts8f/1rU+MNmdtCf9v6o8VVm9oY/7ZtmZv54mZn9yB/fYmZNUcusN7MD/m19YM9cJIPm108Ju4SMSKRtDgJ/6pzbbmaTgG1m1gxMBz4ErHDO9ZnZNAAzWwqsA5YBs4BfmtkS59wQ8C3gU8Bm4OfAvcBzwANAp3NukZmtAx4DPm5mtcCjwGrA+Y+9wTnXGdQLICLBibuF4pw75Zzb7t/vBvYAjcBngK865/r8aa3+Ih8C/sU51+ecOwIcBNaY2UxgsnPuFefFFT4FfDhqme/79/8v8D5/6+X9QLNzrsNvIs14TUhEstCEdsr6H0VuALYAS4Db/I8oL5rZjf5sjcBbUYud8Mca/ftjx0ct45wbBLqAunHWNbauT5nZVjPb2tbWNpGnJAWmv7+f3t6+sMvIWwk3FDOrBn4MfN45dw7v41INsBb4EvC0v1VhMRZ344yT5DKXB5z7jnNutXNudUNDzItxiwCwYccRMOV5p0tCDcXMSvCayQ+cc8/6wyeAZ53nVWAYqPfH50QtPhs46Y/PjjFO9DJmVgxMATrGWZdIUj665hoqK8rHnafjXA9HW7syVFF+SeRbHgO+C+xxzn09atJPgbv8eZYApcAZYAOwzv/mZj6wGHjVOXcK6Daztf46PwH8zF/XBmDkG5yPAv/u72fZCNxjZjVmVgPc44+JpE1b9wDTJ1eEXUZOSuRbnluBPwLeMLMd/tj/AJ4EnjSzXUA/sN5vArvN7GngTbxviD7rf8MD3o7c7wEVeN/uPOePfxf4JzM7iLdlsg7AOddhZn8JvObP9xfOuY4kn6tIQq5pnBp2CTnLvB6QP1avXu0U9CUT9fKB09y0oIHiIh08Ho+ZbXPOrY41Ta+eCDCvrlrNJAB6BUWA2QFdF+U3B44Hsp5cpYYiEqCaiklhlxAqNRSRAF03uybsEkKlhiIigVFDEZHAqKGISGDUUKQgtZ/t5mRHd9hl5B01FClIFwcdM6ZWp7yefW+dYtOOnQnP39rZS1tXb8qPm60K47p0ImM01k8OZD3XzJlJY03i65pWUxnI42YrbaGIpKi6WmFhI9RQRNLk4sAQw8PDYZeRUWooIlFeOxDc5Xb+z8tHeOLFQ4GtLxdoH4pIlHkB7VsBeO+SuisvL5jn1FBEokyrSf2bnxHXziq8w/D1kUdEAqOGIiKBUUMRkcCkFEXqT/+imTkzq48aUxSpSAFKZAtlJIr0OrwMns/6caOY2RzgbuDSZarGRJHeCzxhZkX+5JEo0sX+bSQF8FIUKfANvChSoqJIbwLWAI/6V78XSdhb7T1hl1AwUokiBe+X/88YHb6lKFLJKoODSgrMlKSjSM3sfuBt51zLmNkyHkUqMp7502vDLqFgJBVFivcx6BHgK7FmjTGW1ihSZRtLEPac7OKlvafDLiOnJRtFuhCYD7SY2VG8iNDtZjaDEKJIlW0sQTjd1UPf4EDYZeS0pKJInXNvOOemOeeanHNNeL/4K51z76AoUslRd143i7uXz44/o1xV0lGkzrmfx5rZOacoUpECpShSKShtnefo6r3IosZpYZeSsxRFKuLrHTJm1U4Ju4y8pbONpaDMqy/sZL900xaKiARGDUVy1sn2bvr69TVvNlFDkZxVWVbMy/tOxJ9RMkYNRXLW1OoK7nrX/LDLkChqKCISGDUUEQmMGoqIBEYNRUQCo4YiIoFRQxGRwKihiEhg1FBEQjYwOMQvW46GXUYg1FBEQlZSXMRvvbsp7DICoYYiErKjred47cipsMsIhBqKSMiapk3mxvkzrxh/q6OXP/zfWxgezp2LoKmhiGSpypIIf7x2HpFIrPCH7KSGIpKl6iaVc+fyGWGXMSFJZxub2eNmttfMdprZT8xsatQyyjYWKUCpZBs3A8udcyuA/cDDoGxjyS6Dg0PxZ5LAJJ1t7Jx73o8NBdjM5RAvZRtLVrhwcYCvPPNC2GUUlKSzjcdM+iSXM3aUbSxZoaK8hEfuvzmQdZ3t7WffqXOBrCufJZVt7Jw7FzX+CN7Hoh+MDMVYXNnGEoqqqspA1nOxf5D9J5QxF0+y2cYj4+uB+4A/cJcTw5RtLHlnxtRKfufGppTWsftEZv7Y7TgWXuNLKtvYH78X+O/A/c653qhFlG0sEsPxjgsZeZxljeEFmSWdbQx8EygDmv1vfzc75z6tbGOR2D6wYm5GHqekuCj+TGmibGMRmRBlG0vWaDneQb79EQvC6c4eNu0IL2Oo7dyFQP5f1FAko+oqS+kbGH2wmRoMVJWXcId/mP1brZ0Zf/z+/n7O9/anvB41FMmo2fXVlJde3nXnnGPjzhN0BfBmnqjnWg7T29sbf8YMqK4opbjYe11ePnw844/fWD+FSVVlKa9H+1CkYF3oG6SsJEIkMvG/q/veOknEjMWzr7zsQL7TPhSRGCrKipNqJgALZjTQcqo94IpynxqKSBJKSkr46I3LJ7zc6Y4uXtp9IA0VZQc1FJEMKioq4tpZuXWNk4lQQ5GccfpsLy/tz/wOyyDVT6lmWs2ktD/OlkOtaX+MWNRQJGdMn1rJ7UvSd7Tpa/tPMDg0nLb1Z9Kc2qpQHlcNRQTv6+vy8lIiljvXbx3PrJpwGkoi5/KI5D0z411zp4VdRs7TFoqIBEYNRUQCo4YiIoFRQxGRwKihiEhg1FAk4149lB/B4HIlNRTJuDULUztD94Vd+2htz/w1QyQ+NRTJOWsXzaOkSG/dbJRKtnGtmTX7mcPN0RGhyjaWdCovL6dmanhXdg9Cb/9g/JlyUCrZxl8GNjnnFgOb/J+VbSxpc/BUe95cLvIbG/fmzXOJlnS2MaPziL/P6JxiZRtL4GbUTA67hMA88jvLsTw5byhaKtnG0/3wLvx/R06EULaxpEV1eQlmxi92vsmFC5kJzZKJSTnbONasMcaUbSyBuXX+HCoqKsIuQ2JIJdv4tP8xBv/fkSu6KNtYUtbTd/WdlpMmpf8CRfnq37btTev6k842ZnQe8XpG5xQr21iS1tF9kX/YtC/sMvJSRXkVw8Ppu4hUKtnGXwWeNrMHgOPAxwCUbSypqqkuY9rk7PtIs3HHMbouDvORG3P3OJi7ls2JP1MKlMsjkqCT7d00TC6npKQk7FJCpVwekQDMqpuUVc3kF7v2cqw1uzbYdQlIkRx17/Jrwy7hCtpCEclSP9t+NOwSJkwNRSRLLaqrDruECVNDEclSy+bVh13ChKmhiEhg1FAk62x6/WDM8We37MhsIRl2+HR2fWOTDDUUyTrvu2FRzPE7Fs/LcCWZVRKJjDqK9Wfb9ye1noEQ41TVUCRn1NXm96Vw5jRMJRK5/Cv5oZVLklrPsHN0XxwIqqwJUUORgtJ9vicvL2wUray4iE2736Kt+2LGH1sNRQrKK4dPxJ8pD1QWD9DccjTjj6sjZaWg3LPimrBLyIi7Vyzh8OmzGX9cbaGI5KgXdh+nvz/2vhIzY+GMzO9zUkMRyVF3LptLaWnskxU7unp57KfPZ3x/kRqKFKTh4WG2HXon7nyvHj6dgWqCVzulkk/eeXPGL4SthiIF58e/fg0zY8G0+FfRX7NgegYqSo+GqaMvlfnKwfgNNFXaKSsF5z/cdiMANZMqQ64ks27KQHPUFopImjXvPMzpzp6wyyASSf/HHzUUKQib9x/h/PnzoTz23SsWML2matx5Xt57nNaOrpjTthxu42xP/6WfT7Z3s/1IdsbFJHLV+yfNrNXMdkWNXW9mm81sh5+HsyZqmnKNJeuUDw3wzpn2sMu4qjULZzGtNnZec21VGX2DQ5d+rptUzg1NV17a4JX9J/n75u1pqzEhzrlxb8DtwEpgV9TY88AH/PsfBF7w7y8FWoAyYD5wCCjyp70K3IwX3vVc1PJ/Anzbv78O+JF/vxY47P9b49+viVfvqlWrnEghGhoacj09F9L+OMBWd5Xfv0SyjV/Ci7YYNQyM7CKfwuXwLeUai4QkEolQWVkeag3JfsvzeWCjmf0N3semW/zxRmBz1HwjWcQDJJhrbGbKNRZJwZHWLubVTxp15nKmJPuInwG+4JybA3wBL6gLQsg1BmUbi0SbP21KKM0Ekm8o64GRjONngJGdshnPNQZlG4tki2QbykngDv/+XcAB/75yjUUKWNx9KGb2z8CdQL2ZnQAeBR4E/s7forgIfAqUayxS6JRtLCITomxjEckINRQRCYwaiogERg1FRAKjhlIANh8+wdtnzuGc48W9hXHVdwmHLrBUANYuuHxM4cmODkYfYygSHG2hZKl/274vLev98A3JpdGF5WJICXiSHDWULPXbK5PPj3l+53E6z8dOjauoCPds1Inadix7r2EiV9JHnjz0W8tnMzgYXmB2kG69ZkbYJcgEaAslD0UiEUpL8+9vxa/2tvLgUzoKOpupoUhKhoeT2xJ6Ye8RznX3jhrb+3Ybh053XnWZqrJi1syezPBwfp0ukk90Lo+kpHnnAWZNrmBZk745KhTjncuTf9vFklF3r1gcdgmSRfSRR0QCo4YiIoFRQ5GUDQ0NMzSUH19TS2rUUCRlZ8710Hn+QthlSBbQTllJ2fSaSWlb9/meC2ARqivL0vYYEhxtoUhW6zzfw3O794ZdhiQoqWxjf/whP794t5l9LWpc2cYB2nakNeV1/GZP7l6yYM70ej66ekXYZUiCEtlC+R5jIkDN7L14EaIrnHPLgL/xx5fiXbV+mb/ME2ZW5C/2Lbyr4y/2byPrfADodM4tAr4BPOavqxbvCvs34eX+POrHaRSUlU2p5wxdP68ugErC4//tkRyQbLbxZ4CvOuf6/HlG/owq2zhgQfwyVVZWBFCJSHzJ7kNZAtzmf0R50cxu9MevlkfcSILZxsCEs40VRSqSHZJtKMVADbAW+BLwtL9VEUq2saJIRbJDsg3lBPCs87wKDAP1hJRtLCLZIdmG8lO8TGPMbAlQCpxB2cYiBS3ZbOMngSf9r5L7gfV+E1C2sUgB0/VQRGRClG2cRk+9uI+jrV1hlzGKc47O7tgXqRZJJzWUFK27ZREza6rDLuMKu07m56fDlsOnwi5BxqGTA1NUWlIUf6YMMzNuu2ZW2GWkRVVp9r3ecpm2UPLYnhPtdIy5EHSuWzR7WtglyDi0hZLHrpud2+fwSO7RFoqIBEYNRUQCo4YiIoFRQxGRwKihiEhg1FBEJDBqKCISGDUUEQmMDmyTgtbbP8ieU+fYc+ocx9t7Od3dx6G2HhbWV3Hfu2dx99LpYZeYU9RQpKCcPHuBX+x+h5OdFzjVdYHW7j46evo53tHLyrk1bDnSwayp5Syor+KHW45RWhzhjiW6rGii1FCkYJzt7efvNu3n/7WcpLd/dBbz4mnVNNZU8J6iOrYd62RDy+WrjaqhJE4NRfJW14UBLg4M0XVhgNePd/L4xv2cOd/HqrlT2Xb8LDMml7F2QR1Dw46XD57h2e1vX7GO1986y6G28yxsyL5LVGQjNRTJS+3n+/jdJ15mYUM1kYhxcWCYZbMmUxwx6qtKWd44hZ6+QbovDrLxzdNXLF8cMd6/bAb/8dYmFtRXhfAMcpMaiuSdo2d6+NeWt6mrLuPf912Z03TT/Fq2HPEuQHXrgtpL4xGDmxfWcc/SGdy3YiZ11Qpon6hELlL9JHAf0OqcWz5m2heBx4EG59wZf+xhvHjRIeC/Ouc2+uOruHyR6p8Dn3POOTMrw0sSXAW0Ax93zh31l1kP/E//4f7KOTeSMBiIC/1DPPHCQarLivnPdywMctUSgp0nzvKN5v2UFBnNe1oZe7nkoohx55IGGiaVcbS9h7LiItp6+vnTe5Ywa0oFK+fVMF9bIylJZAvle8A/4P3SX2Jmc4C7geNRY9HZxrOAX5rZEv/K9yPZxpvxGsq9eFe+v5RtbGbr8LKNPx6VbbwaL+Brm5lt8GNJU3a+b5A9J8+y+XA7xzt6efC2BUQiytDNVduOdfL739lM/9AwS2dOGtVM5tZW8pEbGvnY6tnMrqkMr8gCkGy2MXjB5n/G6DS/nMk2Pth6nqdeOU5lSYTT5/rYdTK7LjQtE/P15n30D3nf3Lx5qpvGmgqqSov4kzsX0vzfbucLdy9RM8mApPahmNn9wNvOuZYxYd6NeFsgI0byiAdIMNvYzJLKNsbb+mHu3LkJPYfr50ylYVIpFy9epKw4wi/3tLJi9tSElpXs0/LW6D8Iq+fV8NcfeRdVZdpNmEkTPvTezCqBR4CvxJocYyxrs40/c8ciiiIR3t04md1vp28LZf+p9rStW2BgaJjzfYOjxl7c30aRPsJmXDLn8iwE5gMtZnYUL3N4u5nNIMeyjRsml/OJWxfynoW1fPuPVgW56lHm1U1J27rFO95krLuuncbA0HCMuSWdJrw96Jx7A7h06XG/qax2zp0xsw3AD83s63g7ZUeyjYfMrNvM1gJb8LKN/95fxUi28StEZRub2Ubgr/1cY/CyjR9O5kmO55bFDdyyOL1HQpaVarM7naIbyoKGKv7qw8u5ZWF9iBUVrqSyjZ1z3401r3NO2caScV0XBigrjvDQXYt48PYFlBUruycsyjaWnHe8vReHY16djiHJhPGyjbUtLjlvbp2+Ds4WusCSiARGDSUB/YNDbHz9KD0Xr/w2QUQu00eeBBhw+3WNVJSXhF2KSFZTQ0lASXERJfrmQCQufeQRkcCooYhIYNRQRCQwaigiEhg1FBEJjBqKiARGDUVEAqOGIiKBKdiG8qPfHGZwcCj+jCKSsII9UvbjtywIuwSRvFOwWygiEjw1FBEJjBqKiARGDUVEAhO3oZjZk2bWama7osYeN7O9ZrbTzH5iZlOjpj1sZgfNbJ+ZvT9qfJWZveFP+6afDoiZlZnZj/zxLWbWFLXMejM74N/WB/WkRSQ9EtlC+R5XRoA2A8udcyuA/fjxFmOyje8FnjCzkQuJjGQbL/ZvI+u8lG2MF2/6mL+ukWzjm4A1wKNRkRoikoWSyjZ2zj3vnBuJatvM5RCvnMk2FpHgBbEP5ZNczti5Wh5xIwlmGwNJZRub2VYz29rW1pbSkxGR5KXUUMzsEbxArx+MDMWYLWuzjUUkWEkfKevvJL0PeJ+7nBaWSrbxiRjZxneOWeaFeHVt27btjJkdm+DTGU89cCbA9aVCtcSmWq6UzjrmXXWKcy7uDWgCdkX9fC9e3GjDmPmWAS1AGV6g+mGgyJ/2GrAWb8vjOeCD/vhngW/799cBT/v3a4EjQI1/OwLUJlJvkDdga6YfU7WollytI6lsY7xvdcqAZv/b383OuU87ZRuLFLS8yzYOmpltdVfJcc001RKbasmeOnSkbHzfCbuAKKolNtVypVDq0BaKiARGWygiEhg1FBEJTEE1FDO71z9p8aCZfTnG9Br/ZMedZvaqmS33x+eY2a/MbI+Z7Tazz0Ut8+dm9raZ7fBvH0xnLf60o/6JljvMbGvUeK2ZNfsnUzYneu5TCq/LNVHPe4eZnTOzzyf7usQ6EXXMdPNPLD3o17Iy3nNI4TVJqpY0vVdSeV0Cfa/EFfb35Rn8Xr4IOAQsAErxjpdZOmaex4FH/fvXApv8+zOBlf79SXgnRC71f/5z4IuZqsX/+ShQH2O9XwO+7N//MvBYumsZs553gHkpvC63AyuJOuZpzPQP4h1uYHjHNG2J9xySeU1SrCXQ90oqtQT9XknkVkhbKGuAg865w865fuBf8E5MjLYU2ATgnNsLNJnZdOfcKefcdn+8G9jDVc4rSnctcdYbfaLl97l8AmYmankfcMg5l/RRyi7GiahjfAh4ynk2A1PNO/F0vOeQzGuSdC1peK+k8rqMJ6nXJZ5CaiiJnGzYAvwugJmtwTvEOPqUAcy7XssNwJao4f/ib2o+meCmY6q1OOB5M9tmZp+KWma6c+4UgP/vtAzUMmId8M9jxib6uiRb63jPIZnXJJVaLgnovZJqLUG+V+IqpIaSyMmGXwVqzGwH8BDwOt4Rv94KzKqBHwOfd86d84e/BSwErgdOAX+bgVpudc6tBD4AfNbMbk/gMdNVC2ZWCtwPPBO1TDKvS7K1JnwiaYDGfcwA3yup1hLkeyWuQorRuNqJi5f4//H/CbwdXXjnDx3xfy7Be4P8wDn3bNQyp0fum9n/Av413bU45076/7aa2U/wNvlfAk6PbHb7m7yt6a7F9wFge/RrkeTrkmytpeM8h2Rek1RqCfq9klItAb9X4iqkLZTXgMVmNt//i7oO2BA9g5lN9acB/DHwknPunP9L9F1gj3Pu62OWif6s+hEg5p74AGupMrNJ/jxVwD1Rj7kBGLlU5nrgZ+msJWqW32fMx50kX5d4NgCf8L/VWAt0+Zvr4z2HZF6TpGtJw3sllVqCfq/EF8Se3Vy54e0N34/3jcAj/tingU/7928GDgB7gWeBGn/8PXibkDuBHf5t5GzpfwLe8KdtAGamuZYFePs0WoDdI8v60+rwdp4e8P9N6OzsZGvxp1UC7cCUMeuc8OuC15ROAQN4f3UfGFOHAf/o1/kGsHq855Dia5JULWl6ryRbS+DvlXg3HXovIoEppI88IpJmaigiEhg1FBEJjBqKiARGDUWkQMQ7yTDG/L9nZm+ad5LjDxNaRt/yiBQG/yjZ83jn/SyPM+9i4GngLudcp5lNc87FPfhNWygiBcLFOMnQzBaa2S/8c31+bWbX+pMeBP7ReamdJNJMQA1FpNB9B3jIObcK+CLwhD++BFhiZi+b2WYzSygGuJDO5RGRKP4JjLcAz3hnDABePA54vWExXoTObODXZrbcOXd2vHWqoYgUrghw1jl3fYxpJ/DytgaAI2a2D6/BvBZj3lErFJEC5LwTPI+Y2cfg0qUk3+1P/inwXn+8Hu8j0OF461RDESkQ5qWAvgJcY2YnzOwB4A+AB8xs5ATCkSvdbQTazexN4FfAl5xz7XEfQ18bi0hQtIUiIoFRQxGRwKihiEhg1FBEJDBqKCISGDUUEQmMGoqIBOb/AxrtyaW/KkzmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tax_shp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_names(nameList,nl,threshold):\n",
    "    '''\n",
    "    fuzzy name matching algorithm - finds best name match \n",
    "    for target name (nameList) against list of name options (nl)\n",
    "    \n",
    "    Keyword arguments:\n",
    "    nameList -- target name\n",
    "    nl -- list of names to try matching with target name\n",
    "    threshold -- threshold for accepting name matches (value between 0 and 1)\n",
    "        i.e a .75 threshold will only consider a name match when best name \n",
    "            match is .75 or greater\n",
    "    '''\n",
    "    \n",
    "    from difflib import SequenceMatcher as SM\n",
    "    from operator import itemgetter\n",
    "    matched_list = []\n",
    "\n",
    "    for j in range(0, len(nameList)):\n",
    "        ratio_list =[]\n",
    "        for i in range(0, len(nl) ):\n",
    "            #calculates a matching score\n",
    "            ratio = SM(None, nameList[j], nl[i]).ratio()\n",
    "            name = nl[i]\n",
    "            #add the name to ration_list and its score \n",
    "            ratio_list.append([name, ratio])\n",
    "\n",
    "            if i == (len(nl)-1):\n",
    "                #sort score from highest to lowest\n",
    "                ratio_list = sorted(ratio_list, key=itemgetter(1), reverse=True)\n",
    "                # only keep match names of a certain threshold\n",
    "                if (ratio_list[0][1] >= threshold):\n",
    "                    matched_list.append(ratio_list[0][0])\n",
    "    return(matched_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_func(blacklist, date_threshold):\n",
    "    '''\n",
    "    for each NB in 'all_NBs' (list of NBs to analyze), this function:\n",
    "    1. identifies Adjacent and Block buildings in relation to the NB\n",
    "    2. identifies joint NBs (nearby buildings that are also NBs and have the \n",
    "        same owner as the NB of interest)\n",
    "    3. identifies whether any of the nearby lots have the same building owner as the NB\n",
    "    4. outputs CSV with the final data: \n",
    "        BBL_Description - description of the lot (Job Filing, Adjacent, Block)\n",
    "        Joint_NB - joint NB status of lot (NB, Adjacent, Lot)\n",
    "        Address - address of NB or same-owner matched lot\n",
    "        NB_Owner - name of NB owner or name of same-owner matched lot owner\n",
    "        Same_Owner - indicator, 1=lot has same owner as NB, 0=otherwise\n",
    "        RPP_Owner_Not_Same - for the NB, was RPP or NB filing name used?\n",
    "                             1=RPP name(s) of NB used, 0=NB filing name use\n",
    "        doc_id - document ID of same-owner matched lot\n",
    "        \n",
    "        \n",
    "    Keyword arguments:\n",
    "    blacklist -- list of document types that should be filtered out\n",
    "    date_threshold -- string of document date to go back to\n",
    "        i.e.'2015-01-01 00:00:00' will keep documents from 2015 to present\n",
    "    lot_in_block -- True or False (default)\n",
    "        does the lot need to be in the block shapefile?\n",
    "        False -- will include NB in output, even if not in shapefile\n",
    "        True -- will break loop and go on to next NB\n",
    "    '''\n",
    "\n",
    "    # initialize dataframe for csv output\n",
    "    the_df = pd.DataFrame()\n",
    "    # initialize list of NB Buildings not in Pluto shapefile\n",
    "    odd_NB_BBLs = []\n",
    "    count = 0\n",
    "    # initialize some columns in shapefile\n",
    "    tax_shp[\"Same_Owner\"] = 0 # 0 - not same owner; 1 - same owner\n",
    "    tax_shp[\"Owner\"] = 0 # NB, Same_Owner, Block\n",
    "    for NB_BBL in tqdm(all_NBs, total=len(all_NBs), position=0, leave=True):\n",
    "        try:\n",
    "            count += 1\n",
    "            if count%50==0:\n",
    "                print(\"on\", str(count), \"of\", str(len(all_NBs)), \"NBs\")\n",
    "\n",
    "            # block of the NB\n",
    "            NB_block = int(df[df[\"BBL\"]==NB_BBL].block.drop_duplicates())\n",
    "            NB_borough = int(df[df[\"BBL\"]==NB_BBL].borough_code.drop_duplicates())\n",
    "            NB_lot = int(df[df[\"BBL\"]==NB_BBL].lot.drop_duplicates())\n",
    "            \n",
    "            #filter shapefile to only the block with that NB\n",
    "            map_block = tax_shp[(tax_shp.BLOCK==NB_block)&(tax_shp.BORO.astype(int)==NB_borough)]\n",
    "\n",
    "            # see if lot is in the block\n",
    "            map_block_test = tax_shp[(tax_shp.BLOCK==NB_block)&(tax_shp.BORO.astype(int)==NB_borough)&(tax_shp.LOT.astype(int)==NB_lot)]\n",
    "            if map_block_test.shape[0]==0:\n",
    "                # list of NB Buildings not in shapefile\n",
    "                odd_NB_BBLs.append(NB_BBL)\n",
    "            \n",
    "            # find adjacent buildings to the NB\n",
    "            map_block[\"ADJACENT\"] = None\n",
    "            for index, building in map_block.iterrows():   \n",
    "                # get 'not disjoint' buildings\n",
    "                neighbors = map_block[~map_block.geometry.disjoint(building.geometry)].BBL.tolist()\n",
    "                # remove own name from the list\n",
    "                neighbors = [ bbl for bbl in neighbors if building.BBL != bbl ]\n",
    "                # add names of neighbors as ADJACENT value\n",
    "                map_block.at[index, \"ADJACENT\"] = neighbors\n",
    "            adj = map_block[map_block.BBL==NB_BBL].ADJACENT.to_list()\n",
    "            near_BBL = list(set([item for sublist in adj for item in sublist if item!=NB_BBL]))\n",
    "\n",
    "            # create list of BBLs only on the block (not adjacent to the NB)\n",
    "            not_adj = map_block[~map_block.BBL.isin(near_BBL)]\n",
    "            not_adj = not_adj[not_adj.BBL!=NB_BBL]\n",
    "\n",
    "            # indicate in shapefile building description: NB, Adjacent, or Block\n",
    "            tax_shp.loc[tax_shp['BBL'] == NB_BBL, 'BBL_description'] = \"NB\"\n",
    "            # if the building as already been marked as NB, do not change it to Adjacent or Block\n",
    "            tax_shp.loc[tax_shp['BBL'].isin(near_BBL), 'BBL_description'] = [\"ADJACENT\" if x != \"NB\" else x for x in tax_shp.loc[tax_shp['BBL'].isin(near_BBL), 'BBL_description']]\n",
    "            already_desc = [\"NB\", \"ADJACENT\"]\n",
    "            tax_shp.loc[tax_shp['BBL'].isin(not_adj.BBL.tolist()), 'BBL_description'] = [\"BLOCK\" if x not in already_desc else x for x in tax_shp.loc[tax_shp['BBL'].isin(not_adj.BBL.tolist()), 'BBL_description']]\n",
    "\n",
    "            ###### Do the adjacent or same-block buildings have the same owner as the NB? #####\n",
    "\n",
    "            # filter BBLs of buildings on same block as NB in Real Properties Legal\n",
    "            rpl_near_BBL =  rpl[rpl.BBL.isin(map_block.BBL.tolist())]\n",
    "\n",
    "            #Get owner names of nearby buildings by connecting \n",
    "            #ACRIS Real Property Legals to Real Property Parties by document_id\n",
    "            docids = list(rpl_near_BBL.document_id)\n",
    "            rpp_near_BBL = rpp[rpp.document_id.isin(docids)]\n",
    "\n",
    "            prop_near_BBL = pd.merge(rpl_near_BBL, rpp_near_BBL, on=\"document_id\", how=\"inner\", indicator=True)\n",
    "\n",
    "            #remove whitespaces from owner name\n",
    "            prop_near_BBL.name = [str(name).strip() for name in prop_near_BBL.name] \n",
    "\n",
    "\n",
    "            ### Check to see if any of the nearby buildings are NBs and the same owner (joint NB)\n",
    "\n",
    "            map_block['RPP_Owner_Not_Same'] = \"-\" # 0= NB name matches RPP name; 1= NB names DOESN'T match RPP name\n",
    "            backup_RPP_Owner_Not_Same = []\n",
    "            nameList = df[df['BBL']== NB_BBL]['owner_s_business_name'].drop_duplicates()\n",
    "\n",
    "            if (nameList==\"NONE\").any() or (nameList==\"nan\").any() or  \"\".join(nameList)=='-' or \"\".join(nameList)=='OWNER' or \"\".join(nameList)=='NA' or \"\".join(nameList)=='.' or \"\".join(nameList)=='N\\A' or \"\".join(nameList)=='N.A.' or \"\".join(nameList)=='N/A'or \"\".join(nameList)=='NOT APPLICABLE' or \"\".join(nameList)=='SELF' or \"\".join(nameList)==\"INDIVIDUAL\":\n",
    "#                 df[df['BBL']== NB_BBL]['owner_s_first_name'] = [name.strip() for name in df[df['BBL']== NB_BBL]['owner_s_first_name']] \n",
    "#                 df[df['BBL']== NB_BBL]['owner_s_last_name'] = [name.strip() for name in df[df['BBL']== NB_BBL]['owner_s_last_name']] \n",
    "                nameList = df[df['BBL']== NB_BBL].name #['owner_s_first_name'] + \" \" +  df[df['BBL']== NB_BBL]['owner_s_last_name']\n",
    "                df.loc[df['BBL']== NB_BBL, 'owner_s_business_name']  = nameList\n",
    "    \n",
    "            # get BBL of nearby lots and see if any of them are NB filings\n",
    "            near_lots = prop_near_BBL[prop_near_BBL.BBL!=NB_BBL]\n",
    "            near_NB = df[df.BBL.isin(list(set(near_lots.BBL)))]\n",
    "\n",
    "            # check that the near NBs have the same owner (using filing name)\n",
    "            matched_list = fuzzy_names(nameList.tolist(),near_NB.owner_s_business_name.tolist(),.9)\n",
    "\n",
    "            # joint lot NBs \n",
    "            joint_NBs = near_NB[near_NB.owner_s_business_name.isin(matched_list)].BBL.tolist()\n",
    "            # include original NB in the joint NBs lot list\n",
    "            joint_NBs.append(NB_BBL)   \n",
    "\n",
    "\n",
    "            ### Check to see if the NB owner is the same as the owner listed in RPP\n",
    "\n",
    "            # Find all document IDs associated with the NB's BBL\n",
    "            NB_BBL_rpl = rpl[rpl.BBL==NB_BBL]\n",
    "            # Connect ACRIS Real Property Legals to Real Property Parties by document_ids to get owner names\n",
    "            NB_BBL_docids = list(NB_BBL_rpl.document_id)\n",
    "            rpp_NB_BBL = rpp[rpp.document_id.isin(NB_BBL_docids)]\n",
    "\n",
    "            # Check if RPP owner name matches NB owner name\n",
    "            adjusted_nl = []\n",
    "            arr = [\"LLC\", \"INC\", \"N.A\", \"NA\", \"N/A\"]\n",
    "            # names need to be adjusted to be 'first last' instead of 'last, first' to match NB filing \n",
    "            nl = rpp_NB_BBL.name.tolist()\n",
    "            for name in nl:\n",
    "                adjust_name = str(name).split(\",\")\n",
    "                adjust_name = [i.strip() for i in adjust_name]\n",
    "                if len(adjust_name)>1:\n",
    "                    if any(re.findall('|'.join(arr), adjust_name[1])):\n",
    "                        adjust_name = adjust_name[0] + \" \" + adjust_name[1]\n",
    "                        adjusted_nl.append(adjust_name)\n",
    "                    else:\n",
    "                        adjust_name = adjust_name[1] + \" \" + adjust_name[0]\n",
    "                        adjusted_nl.append(adjust_name)\n",
    "                if len(adjust_name)==1:\n",
    "                    adjusted_nl.append(\"\".join(adjust_name))\n",
    "\n",
    "            # Check for NB name in RPP \n",
    "            matched_list_NB_RPP = fuzzy_names(nameList.tolist(),adjusted_nl,.9)\n",
    "\n",
    "            #### Need to use RPL name instead of NB owner name\n",
    "                 # NB name does not match in RPP and there was RPL data on NB (NB filing name!=RPP name)\n",
    "            if (len(matched_list_NB_RPP)==0) and (NB_BBL_rpl.shape[0]>=1):\n",
    "                map_block.loc[map_block.BBL==NB_BBL, 'RPP_Owner_Not_Same'] = 1\n",
    "                backup_RPP_Owner_Not_Same.append(1)\n",
    "\n",
    "                # keep only documents from the past decade, and certain document types\n",
    "                prop_near_BBL = pd.merge(prop_near_BBL, rpm, on=\"document_id\", how=\"left\")\n",
    "                prop_near_BBL = prop_near_BBL[(prop_near_BBL.doc_date > date_threshold) & ~(prop_near_BBL.doc_type.isin(blacklist))]\n",
    "\n",
    "                # list of RPP names associated with the building\n",
    "                NB_prop = prop_near_BBL[prop_near_BBL.BBL==NB_BBL]\n",
    "\n",
    "                # keep most recent names associated with the NB\n",
    "                NB_prop = NB_prop.loc[NB_prop['doc_date']==NB_prop['doc_date'].max()]\n",
    "\n",
    "                if NB_prop.shape[0] >=1:\n",
    "                    nameList = NB_prop.name.drop_duplicates().tolist()\n",
    "                elif NB_prop.shape[0] ==0:\n",
    "                    # sometimes NB_prop is blank, giving no name to the NB - this fixes\n",
    "                    nameList = df[df['BBL']== NB_BBL]['owner_s_business_name'].drop_duplicates().tolist()\n",
    "\n",
    "                # Search owner names in nearby buildings to match owner of RPP\n",
    "                    # remove NB BBL from list of owner names\n",
    "                prop_near_BBL = prop_near_BBL[prop_near_BBL.BBL!=NB_BBL]\n",
    "                # exclude joint NB BBLs from same_owner matching\n",
    "                if len(joint_NBs) > 1:\n",
    "                    prop_near_BBL = prop_near_BBL[~prop_near_BBL.BBL.isin(joint_NBs)]\n",
    "\n",
    "                # filter party of certain document types\n",
    "                prop_near_BBL = prop_near_BBL[~((prop_near_BBL.doc_type.isin([\"DEED\"])) & (prop_near_BBL.party_type==1))]\n",
    "                prop_near_BBL = prop_near_BBL[~((prop_near_BBL.doc_type.isin([\"RPTT\"])) & (prop_near_BBL.party_type==1))]\n",
    "                prop_near_BBL = prop_near_BBL[~((prop_near_BBL.doc_type.isin([\"AALR\"])) & (prop_near_BBL.party_type==2))]\n",
    "                prop_near_BBL = prop_near_BBL[~((prop_near_BBL.doc_type.isin([\"AL&R\"])) & (prop_near_BBL.party_type==2))]\n",
    "   \n",
    "                nl = prop_near_BBL.name.tolist() \n",
    "\n",
    "                matched_list = fuzzy_names(nameList,nl,.75)\n",
    "\n",
    "                # find BBLs of other nearby buildings that the NB owner owns\n",
    "                near_BBL_owner = prop_near_BBL[prop_near_BBL.name.isin(matched_list)]\n",
    "                # of the nearby BBLs that the NB owner also owns, keep most recent only for output\n",
    "                near_BBL_owner = near_BBL_owner.loc[near_BBL_owner.groupby('BBL').doc_date.idxmax()]\n",
    "\n",
    "                same_owner = []\n",
    "                for bbl in near_BBL_owner.BBL.tolist():\n",
    "                    if bbl != NB_BBL:\n",
    "                        same_owner.append(bbl)\n",
    "\n",
    "                map_block['doc_id'] = \"-\"      \n",
    "                map_block['NB_OWNER'] = \"-\"\n",
    "                if (len(same_owner)>0):\n",
    "                    if len(near_BBL_owner.name.drop_duplicates().tolist())==1:\n",
    "                        map_block.loc[map_block.BBL.isin(same_owner), 'NB_OWNER'] = near_BBL_owner.name.drop_duplicates().tolist()\n",
    "\n",
    "                    for i,j,k in zip(same_owner, near_BBL_owner.name.tolist(), near_BBL_owner.document_id.tolist()):\n",
    "                        map_block.loc[map_block.BBL==i, 'NB_OWNER'] = j\n",
    "                        map_block.loc[map_block.BBL==i, 'doc_id'] = k\n",
    "\n",
    "            ### Proceed as normal (NB filing name==RPP name)\n",
    "                # NB name does match in RPP or there was no RPL data on NB\n",
    "            if (len(matched_list_NB_RPP)>=1) or (NB_BBL_rpl.shape[0]==0):\n",
    "                map_block.loc[map_block.BBL==NB_BBL, 'RPP_Owner_Not_Same'] = 0\n",
    "                backup_RPP_Owner_Not_Same.append(1)\n",
    "\n",
    "                # keep only documents from the past decade, and certain document types\n",
    "                prop_near_BBL = pd.merge(prop_near_BBL, rpm, on=\"document_id\", how=\"left\")\n",
    "                prop_near_BBL = prop_near_BBL[(prop_near_BBL.doc_date > date_threshold) & ~(prop_near_BBL.doc_type.isin(blacklist))] \n",
    "\n",
    "                # Search owner names in nearby buildings to match owner of NB\n",
    "                    # remove NB BBL from list of owner names\n",
    "                prop_near_BBL = prop_near_BBL[prop_near_BBL.BBL!=NB_BBL]\n",
    "                    # exclude joint NB BBLs from same_owner matching\n",
    "                if len(joint_NBs) > 1:\n",
    "                     prop_near_BBL = prop_near_BBL[~prop_near_BBL.BBL.isin(joint_NBs)]\n",
    "\n",
    "                # filter party of certain document types\n",
    "                prop_near_BBL = prop_near_BBL[~((prop_near_BBL.doc_type.isin([\"DEED\"])) & (prop_near_BBL.party_type==1))]\n",
    "                prop_near_BBL = prop_near_BBL[~((prop_near_BBL.doc_type.isin([\"RPTT\"])) & (prop_near_BBL.party_type==1))]\n",
    "                prop_near_BBL = prop_near_BBL[~((prop_near_BBL.doc_type.isin([\"AALR\"])) & (prop_near_BBL.party_type==2))]\n",
    "                prop_near_BBL = prop_near_BBL[~((prop_near_BBL.doc_type.isin([\"AL&R\"])) & (prop_near_BBL.party_type==2))]\n",
    "\n",
    "                nl = prop_near_BBL.name.tolist() \n",
    "\n",
    "                adjusted_nl = []\n",
    "                # names need to be adjust to be 'first last' instead of 'last, first'\n",
    "                for name in nl:\n",
    "                    adjust_name = str(name).split(\",\")\n",
    "                    adjust_name = [i.strip() for i in adjust_name]\n",
    "                    if len(adjust_name)>1:\n",
    "                        if any(re.findall('|'.join(arr), adjust_name[1])):\n",
    "                            adjust_name = adjust_name[0] + \" \" + adjust_name[1]\n",
    "                            adjusted_nl.append(adjust_name)\n",
    "                        else:\n",
    "                            adjust_name = adjust_name[1] + \" \" + adjust_name[0]\n",
    "                            adjusted_nl.append(adjust_name)       \n",
    "                    if len(adjust_name)==1:\n",
    "                        adjusted_nl.append(\"\".join(adjust_name))\n",
    "\n",
    "                matched_list = fuzzy_names(nameList.tolist(),adjusted_nl,.75)\n",
    "\n",
    "                # find original documented name of match, so in final output, it doesn't show\n",
    "                # up as 'last, first'\n",
    "                if len(matched_list)==1:\n",
    "                    for ind, name in enumerate(adjusted_nl):\n",
    "                        if name in matched_list:\n",
    "                            same_owner_ind = ind\n",
    "\n",
    "                    near_BBL_owner = prop_near_BBL[prop_near_BBL.name.isin([nl[same_owner_ind]])]\n",
    "\n",
    "                if len(matched_list)>1:\n",
    "                    for ind, name in enumerate(adjusted_nl):\n",
    "                        if name in matched_list:\n",
    "                            same_owner_ind = ind\n",
    "\n",
    "                    nl = np.array(nl)\n",
    "                    near_BBL_owner = prop_near_BBL[prop_near_BBL.name.isin(list(nl[same_owner_ind]))]\n",
    "\n",
    "                # will be empty, but will restart df from last loop \n",
    "                if len(matched_list)==0:\n",
    "                    near_BBL_owner = prop_near_BBL[prop_near_BBL.name.isin(matched_list)]\n",
    "\n",
    "                same_owner = []\n",
    "                for bbl in near_BBL_owner.BBL.tolist():\n",
    "                    if bbl != NB_BBL:\n",
    "                        same_owner.append(bbl)\n",
    "\n",
    "                # find BBLs of other nearby buildings that the NB owner owns\n",
    "                map_block['doc_id'] = \"-\" \n",
    "                map_block['NB_OWNER'] = \"-\"\n",
    "                if (len(same_owner)>0):\n",
    "                    map_block.loc[map_block.BBL.isin(same_owner), 'NB_OWNER'] = near_BBL_owner.name.drop_duplicates().tolist()\n",
    "\n",
    "                    for i,j,k in zip(same_owner, near_BBL_owner.name.tolist(), near_BBL_owner.document_id.tolist()):\n",
    "                        map_block.loc[map_block.BBL==i, 'NB_OWNER'] = j\n",
    "                        map_block.loc[map_block.BBL==i, 'doc_id'] = k\n",
    "\n",
    "                        \n",
    "        ### uncomment this section if you want owner name and document IDs of associated joint NBs      \n",
    "#                 # If no success, just in case, search other NBs first/last names to see if any of those have the same owner \n",
    "#                 near_nb = []\n",
    "#                 if (len(same_owner)==0): #==True: \n",
    "#                     nl = df['name'].tolist()\n",
    "#                     matched_list = fuzzy_names(nameList.tolist(),nl,.75)\n",
    "\n",
    "#                     near_BBL_owner = df[df.name.isin(matched_list)]\n",
    "#                     near_BBL_owner = near_BBL_owner.drop_duplicates(\"BBL\")\n",
    "\n",
    "#                     for bbl in near_BBL_owner.BBL.tolist():\n",
    "#                         if bbl != NB_BBL:\n",
    "#                             near_nb.append(bbl)\n",
    "\n",
    "#                     map_block.loc[map_block.BBL.isin(near_nb), 'NB_OWNER'] = near_BBL_owner.name.drop_duplicates().tolist()\n",
    "\n",
    "#                 # If no success again, just in case, search other NBs organization names to see if any of those have the same owner      \n",
    "#                 if (len(same_owner)==0):  \n",
    "#                     nl = df.owner_s_business_name.tolist()\n",
    "#                     matched_list = fuzzy_names(nameList.tolist(),nl,.75)\n",
    "\n",
    "#                     near_BBL_owner = df[df.owner_s_business_name.isin(matched_list)]\n",
    "#                     near_BBL_owner = near_BBL_owner.drop_duplicates(\"BBL\")\n",
    "\n",
    "#                     for bbl in near_BBL_owner.BBL.tolist():\n",
    "#                         if bbl != NB_BBL:\n",
    "#                             near_nb.append(bbl)\n",
    "\n",
    "#                     # sometimes there are very similar (but still slightly different) names\n",
    "#                     try:\n",
    "#                         map_block.loc[map_block.BBL.isin(near_nb), 'NB_OWNER'] = near_BBL_owner.owner_s_business_name.drop_duplicates().tolist()\n",
    "#                     except:\n",
    "#                         map_block.loc[map_block.BBL.isin(near_nb), 'NB_OWNER'] = near_BBL_owner.owner_s_business_name.drop_duplicates().tolist()[0]\n",
    "\n",
    "            # correct the descriptions of adjacent/block buildings if there are joint NBs\n",
    "            if len(joint_NBs) > 1:\n",
    "                map_block[\"ADJACENT_UPDATE\"] = None\n",
    "                for index, building in map_block.iterrows():   \n",
    "                    # get 'not disjoint' buildings\n",
    "                    neighbors = map_block[~map_block.geometry.disjoint(building.geometry)].BBL.tolist()\n",
    "                    # remove own name from the list\n",
    "                    neighbors = [ bbl for bbl in neighbors if building.BBL != bbl ]\n",
    "                    # add names of neighbors as ADJACENT value\n",
    "                    map_block.at[index, \"ADJACENT_UPDATE\"] = neighbors\n",
    "\n",
    "                adj_update = map_block[map_block.BBL.isin(joint_NBs)].ADJACENT_UPDATE.to_list()\n",
    "                near_BBL_update = [item for sublist in adj_update for item in sublist if item not in joint_NBs]\n",
    "\n",
    "                # update list of BBLs only on the block (not adjacent to the NB)\n",
    "                not_adj_update = map_block[~map_block.BBL.isin(near_BBL_update)]\n",
    "                not_adj_update = not_adj_update[~not_adj_update.BBL.isin(joint_NBs)]\n",
    "\n",
    "\n",
    "            # indicate in the shapefile building description: NB, Adjacent, or Block\n",
    "            tax_shp.loc[tax_shp['BBL'] == NB_BBL, 'BBL_description'] = \"NB\"\n",
    "            # if the building has already been marked as NB, do not change it to Adjacent or Block\n",
    "            tax_shp.loc[tax_shp['BBL'].isin(near_BBL), 'BBL_description'] = [\"ADJACENT\" if x != \"NB\" else x for x in tax_shp.loc[tax_shp['BBL'].isin(near_BBL), 'BBL_description']]\n",
    "            already_desc = [\"NB\", \"ADJACENT\"]\n",
    "            tax_shp.loc[tax_shp['BBL'].isin(not_adj.BBL.tolist()), 'BBL_description'] = [\"BLOCK\" if x not in already_desc else x for x in tax_shp.loc[tax_shp['BBL'].isin(not_adj.BBL.tolist()), 'BBL_description']]\n",
    "\n",
    "\n",
    "            # indicate in shapefile joint NBs: NB (all those on block with same owner), Adjacent, or Block\n",
    "            if len(joint_NBs) > 1:\n",
    "                tax_shp.loc[tax_shp['BBL'].isin(joint_NBs), 'Joint_NBs'] = \"NB\"\n",
    "                # if the building has already been marked as NB, do not change it to Adjacent or Block\n",
    "                tax_shp.loc[tax_shp['BBL'].isin(near_BBL_update), 'Joint_NBs'] = [\"ADJACENT\" if x != \"NB\" else x for x in tax_shp.loc[tax_shp['BBL'].isin(near_BBL_update), 'Joint_NBs']]\n",
    "                already_desc = [\"NB\", \"ADJACENT\"]\n",
    "                tax_shp.loc[tax_shp['BBL'].isin(not_adj_update.BBL.tolist()), 'Joint_NBs'] = [\"BLOCK\" if x not in already_desc else x for x in tax_shp.loc[tax_shp['BBL'].isin(not_adj_update.BBL.tolist()), 'Joint_NBs']]\n",
    "            if len(joint_NBs)==1:\n",
    "                tax_shp.loc[tax_shp['BBL'].isin(joint_NBs), 'Joint_NBs'] = \"NB\"\n",
    "                # if the building has already been marked as NB, do not change it to Adjacent or Block\n",
    "                tax_shp.loc[tax_shp['BBL'].isin(near_BBL), 'Joint_NBs'] = [\"ADJACENT\" if x != \"NB\" else x for x in tax_shp.loc[tax_shp['BBL'].isin(near_BBL), 'Joint_NBs']]\n",
    "                already_desc = [\"NB\", \"ADJACENT\"]\n",
    "                tax_shp.loc[tax_shp['BBL'].isin(not_adj.BBL.tolist()), 'Joint_NBs'] = [\"BLOCK\" if x not in already_desc else x for x in tax_shp.loc[tax_shp['BBL'].isin(not_adj.BBL.tolist()), 'Joint_NBs']]\n",
    "\n",
    "\n",
    "            # Make buildings on the same block as the NB with the same owner '1'\n",
    "            tax_shp.loc[tax_shp['BBL'].isin(same_owner), 'Same_Owner'] = 1\n",
    "\n",
    "            # indicate in shapefile building owner: NB, Same Owner as NB, and Block\n",
    "            tax_shp.loc[tax_shp['BBL'] == NB_BBL, 'Owner'] = \"NB\"\n",
    "            if len(joint_NBs) > 1:\n",
    "                tax_shp.loc[tax_shp['BBL'].isin(joint_NBs), 'Owner'] = \"NB\"\n",
    "            # if the building has already been marked as NB, do not change it to Same Owner as NB or Block\n",
    "            tax_shp.loc[tax_shp['BBL'].isin(same_owner), 'Owner'] = [\"Same Owner as NB\" if x != \"NB\" else x for x in tax_shp.loc[tax_shp['BBL'].isin(same_owner), 'Owner']]\n",
    "            # if the building has already been marked as NB or Same Owner, do not change it to Block\n",
    "            already_own = [\"NB\", \"Same Owner as NB\"]\n",
    "            adj_list = [item for sublist in adj for item in sublist]\n",
    "            tax_shp.loc[tax_shp['BBL'].isin(adj_list), 'Owner'] = [\"Block\" if x not in already_own else x for x in tax_shp.loc[tax_shp['BBL'].isin(adj_list), 'Owner']]\n",
    "            tax_shp.loc[tax_shp['BBL'].isin(not_adj.BBL.tolist()), 'Owner'] = [\"Block\" if x not in already_own else x for x in tax_shp.loc[tax_shp['BBL'].isin(not_adj.BBL.tolist()), 'Owner']]\n",
    "\n",
    "\n",
    "            #### CSV output ####\n",
    "\n",
    "            # if NB BBL is not in shapfile, need to create a custom row that includes NB data for output\n",
    "            if map_block[map_block.BBL==NB_BBL].shape[0]==0:\n",
    "                map_block = map_block.append(pd.Series(), ignore_index=True)\n",
    "                map_block.loc[map_block.BBL.isna(), \"BBL\"] = NB_BBL\n",
    "                map_block.loc[map_block.BBL==NB_BBL, \"BORO\"] = NB_borough\n",
    "                map_block.loc[map_block.BBL==NB_BBL, \"RPP_Owner_Not_Same\"] = backup_RPP_Owner_Not_Same\n",
    "                map_block.loc[map_block.BBL==NB_BBL, \"doc_id\"] = \"-\"\n",
    "\n",
    "            # Create column of all BBLs (NB, adjacent, on block)                \n",
    "            BBL_col = [NB_BBL] + near_BBL + not_adj.BBL.tolist()\n",
    "\n",
    "            ## Create job filing column\n",
    "            job_filing = [\"NB\"]\n",
    "            other_buildings = [\"-\"] * (len(BBL_col)-1)\n",
    "            job_filing += other_buildings\n",
    "\n",
    "            # Create building description column\n",
    "            nb_desc = [\"Job Filing\"]\n",
    "            adj_desc = [\"Adjacent\"] * len(near_BBL)\n",
    "            block_desc = [\"Block\"] * len(not_adj)\n",
    "            building_desc = nb_desc + adj_desc + block_desc\n",
    "\n",
    "            # Create joint_NBs description column\n",
    "            map_block['JOINT_NBs'] = \"-\"\n",
    "            if len(joint_NBs) > 1:\n",
    "                map_block.loc[map_block.BBL.isin(joint_NBs), 'JOINT_NBs'] = \"NB\"\n",
    "                map_block.loc[map_block.BBL.isin(near_BBL_update), 'JOINT_NBs'] = \"Adjacent\"\n",
    "                map_block.loc[map_block.BBL.isin(not_adj_update.BBL.tolist()), 'JOINT_NBs'] = \"Block\"\n",
    "            if len(joint_NBs)==1:\n",
    "                map_block.loc[map_block.BBL==NB_BBL, 'JOINT_NBs'] = \"NB\"\n",
    "                map_block.loc[map_block.BBL.isin(near_BBL), 'JOINT_NBs'] = \"Adjacent\"\n",
    "                map_block.loc[map_block.BBL.isin(not_adj.BBL.tolist()), 'JOINT_NBs'] = \"Block\"\n",
    "\n",
    "            # NB address column\n",
    "            NB_ADDRESS = list(df[df['BBL']== NB_BBL].NB_ADDRESS.drop_duplicates())\n",
    "             # in case there are multiple addresses listed for the same NB, chose the first address listed\n",
    "            if (len(NB_ADDRESS)>1):\n",
    "                NB_ADDRESS = NB_ADDRESS[0]\n",
    "\n",
    "            # indicator column - 1 near BBL has same owner as NB, None otherwise\n",
    "            map_block[\"SAME_OWN\"] = 0\n",
    "            sameown = map_block[map_block.BBL.isin(same_owner)]\n",
    "            map_block.loc[sameown.index, 'SAME_OWN'] = 1\n",
    "\n",
    "            map_block = map_block.set_index('BBL')\n",
    "\n",
    "            #make sure all nearby lots are in NYC lot shapefile\n",
    "            map_block = map_block.loc[[i for i in BBL_col if i in map_block.index.tolist()]]\n",
    "            map_block['NB_ADDRESS'] = \"-\"\n",
    "            NB_OWNER = [\"; \".join(nameList)]\n",
    "\n",
    "            map_block.loc[map_block.index == NB_BBL, 'NB_OWNER'] = NB_OWNER\n",
    "            map_block.loc[map_block.index == NB_BBL, 'NB_ADDRESS'] = NB_ADDRESS\n",
    "            near_address = near_BBL_owner[near_BBL_owner.BBL.isin(same_owner)]\n",
    "            try:\n",
    "                street_number = [\"\" if x == \"nan\" else x.strip() for x in near_address.street_number.tolist()]\n",
    "            except:\n",
    "                bool_near_owner = near_BBL_owner.BBL.isin(same_owner)\n",
    "                near_address = near_BBL_owner[bool_near_owner]\n",
    "                near_address = near_address[near_address.block==NB_block]\n",
    "                street_number = [\"\" if x == \"nan\" else x.strip() for x in near_address.house__.tolist()]\n",
    "            street_name = [\"\" if x == \"nan\" else x.strip() for x in near_address.street_name.tolist()]\n",
    "            near_address = [m+str(\" \")+str(n) for m,n in zip(street_number, street_name)]\n",
    "            near_address = [\"\" if x == \" \" else x for x in near_address]\n",
    "            near_address = [x[2:] if x.split()[0] == \"\" else x for x in near_address]\n",
    "\n",
    "            if (len(map_block.loc[map_block.index.isin(same_owner)])==1):\n",
    "                near_address = near_address[0]\n",
    "                map_block.loc[map_block.index.isin(same_owner), 'NB_ADDRESS'] = near_address\n",
    "            if (len(map_block.loc[map_block.index.isin(same_owner)])==len(near_address)):\n",
    "                map_block.loc[map_block.index.isin(same_owner), 'NB_ADDRESS'] = near_address\n",
    "            try:\n",
    "                if (len(map_block.loc[map_block.index.isin(same_owner)])>1) & (len(map_block.loc[map_block.index.isin(same_owner)])!=len(near_address)):\n",
    "                    near_address = list(dict.fromkeys(near_address))\n",
    "                    map_block.loc[map_block.index.isin(same_owner), 'NB_ADDRESS'] = near_address  \n",
    "            except:\n",
    "                if (len(map_block.loc[map_block.index.isin(same_owner)])!=len(near_address)):\n",
    "                    map_block.loc[map_block.index.isin(same_owner), 'NB_ADDRESS'] = [\"-\"] * len(map_block.loc[map_block.index.isin(same_owner), 'NB_ADDRESS'])\n",
    "\n",
    "            # add dash if there's a blank\n",
    "            map_block.NB_ADDRESS = [\"-\" if x == \"\" else x for x in list(map_block.NB_ADDRESS)]\n",
    "\n",
    "            # Bind all columns together to create csv\n",
    "            csvdf = pd.DataFrame(list(zip(BBL_col, job_filing, building_desc, list(map_block.JOINT_NBs), list(map_block.NB_ADDRESS), list(map_block.NB_OWNER), list(map_block.SAME_OWN), list(map_block.RPP_Owner_Not_Same), list(map_block.doc_id))), \n",
    "                               columns =['BBL', 'Job_Filing', 'BBL_Description', 'Joint_NBs','Address', 'NB_Owner', \"Same_Owner\", \"RPP_Owner_Not_Same\", \"doc_id\"])\n",
    "\n",
    "            the_df = the_df.append(csvdf, ignore_index=True)\n",
    "\n",
    "        except:\n",
    "            # list of NB Buildings not in shapefile\n",
    "            odd_NB_BBLs.append(NB_BBL)\n",
    "            \n",
    "    return(the_df, odd_NB_BBLs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define list of NBs to analyze in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of NBs to run through in the model\n",
    "all_NBs = list(df.BBL.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_NBs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "### set path for data output\n",
    "model_output = \"model_output/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist =  [\"PREL\", \"REL\", \"RTXL\", \"SAGE\", \"TERA\", \"TL&R\", \"TLS\", \"SAT\", \"CERT\",\n",
    "     \"ASST\", \"DECL\",\"EASE\", \"AGMT\", \"MTGE\",\"AALR\",\"AIRRIGHT\",\"CDEC\",\"CORRD\",\n",
    "     \"CTOR\",\"DEEDO\",\"RPTT&RET\", \"PAT\", \"MCON\"]\n",
    "\n",
    "date_threshold = str(int(s[:4])-2)+'-01-01 00:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1b141239a14a0d929e15acb930b406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on 50 of 100 NBs\n",
      "on 100 of 100 NBs\n",
      "\n",
      "saved Filter02_16!\n"
     ]
    }
   ],
   "source": [
    "tax_shp = gpd.read_file(shapefile_saved_path + \"NB_lots_blocks.shp\")\n",
    "\n",
    "## main loop here\n",
    "the_df, odd_NB_BBLs = loop_func(blacklist, date_threshold)\n",
    "# odd_NB_BBLs = list of NBs not in shapefile\n",
    "\n",
    "## save as \"FilterYear_#ofDocsBlacklisted\"\n",
    "the_df.to_csv(model_output+\"Filter\"+str(int(s[2:4]) - int(date_threshold[2:4])).zfill(2)+\"_\"+ str(len(blacklist)-9)+\".csv\", index=False)\n",
    "\n",
    "# join output with Real Property Master's for information on document types\n",
    "final = pd.merge(the_df, rpm, left_on=\"doc_id\", right_on=\"document_id\", how=\"left\")\n",
    "final = final.fillna(\"-\")\n",
    "final = final.drop(\"document_id\", axis=1)\n",
    "\n",
    "## final csv\n",
    "final.to_csv(model_output+\"Filter\"+str(int(s[2:4]) - int(date_threshold[2:4])).zfill(2)+\"_\"+str(len(blacklist)-9)+\"-doc_data.csv\", index=False)\n",
    "print('saved'+\" Filter\"+str(int(s[2:4]) - int(date_threshold[2:4])).zfill(2)+\"_\"+str(len(blacklist)-7)+\"!\")\n",
    "\n",
    "# list of BBLs not in the shapefile\n",
    "d = {'BBL': odd_NB_BBLs}\n",
    "odd_NB_BBLs_df = pd.DataFrame(data=d)\n",
    "odd_NB_BBLs_df.to_csv(model_output+\"Filter\"+str(int(s[2:4]) - int(date_threshold[2:4])).zfill(2)+\"_\"+str(len(blacklist)-9)+\"-BBLs_not_in_shp.csv\", index=False)\n",
    "\n",
    "\n",
    "## save final shapefile\n",
    "    ## removes lots not analyzed in run\n",
    "tax_shp = tax_shp[~tax_shp.BBL_description.isna()] \n",
    "tax_shp.to_file(model_output+\"Filter\"+str(int(s[2:4]) - int(date_threshold[2:4])).zfill(2)+\"_\"+str(len(blacklist)-9)+\".shp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
